# -*- coding: utf-8 -*-
"""gcoherence.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n6eVTw4fiKWxNuRr5RY4hdCokyMXbyRu
"""

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from typing import Tuple
import soundfile as sf  # safer for multi-channel WAV

# -------------------------------
# Core function (noise suppression with coherence)
# -------------------------------
def process_multi_channel_coherence(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray]:
    """
    tf_maps: (K, L, M) complex STFT maps, K=channels, L=freq bins, M=time frames
    calc_coherence: function(x,y) -> coherence matrix (L,M)
    """
    K, L, M = tf_maps.shape
    if K < 2:
        raise ValueError("At least 2 channels are required for coherence analysis")

    num_pairs = K * (K - 1) // 2
    if logging:
        print(f"[COHERENCE] Processing {K} channels, {num_pairs} channel pairs")
        print(f"[COHERENCE] TF map shape: {L}×{M}")

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            if logging:
                print(f"[COHERENCE] Pair ({i}, {j})")

            coherence = calc_coherence(tf_maps[i], tf_maps[j])  # (L, M)
            coherence_streams[pair_idx] = coherence

            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    # Threshold mask
    coherence_mask = max_coherence >= coherence_threshold

    # Average TF from the best coherent pair at each bin
    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0  # noise suppressed

    if logging:
        coherence_stats = {
            'mean': np.mean(max_coherence),
            'std': np.std(max_coherence),
            'min': np.min(max_coherence),
            'max': np.max(max_coherence),
            'above_threshold': np.sum(coherence_mask) / (L * M) * 100
        }
        print("[COHERENCE] Stats:")
        for k, v in coherence_stats.items():
            print(f"  {k}: {v:.3f}" if isinstance(v, float) else f"  {k}: {v}")

    return average_tf_map, coherence_mask


def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    """Convert linear pair index back to channel indices (i,j)."""
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j

# -------------------------------
# Example coherence calculator
# -------------------------------
def simple_coherence(x: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Pixel-wise coherence: |X*Y| / (|X||Y|)"""
    eps = 1e-8
    return np.abs(x * np.conj(y)) / (np.abs(x) * np.abs(y) + eps)

# -------------------------------
# Demo pipeline with plotting
# -------------------------------
if __name__ == "__main__":
    # ------------------------------
    # LOAD YOUR OWN MULTI-CHANNEL AUDIO
    # ------------------------------
    audio_file_path = "/content/DroneSound_noMuff.wav"  # <-- Update this
    y, sr = sf.read(audio_file_path)  # preserves all channels

    # Ensure y is shape (channels, samples)
    if y.ndim == 1:  # mono
        y = y[np.newaxis, :]
    else:
        y = y.T  # shape: (channels, samples)

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    # STFT for each channel
    n_fft = 1024
    hop_length = 512
    tf_maps = np.array([librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)])

    # Process coherence
    avg_tf_map, coherence_mask = process_multi_channel_coherence(
        tf_maps, simple_coherence, coherence_threshold=0.6, logging=True
    )

    # -------------------------------
    # PLOTS
    # -------------------------------
    fig, axs = plt.subplots(num_channels, 3, figsize=(15, 3*num_channels))

    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    masked_tf = np.abs(avg_tf_map)

    for ch in range(num_channels):
        # Raw TF per channel
        librosa.display.specshow(20*np.log10(np.abs(tf_maps[ch])+1e-8),
                                 sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch, 0])
        axs[ch, 0].set_title(f"Channel {ch} TF Map")

        # Average TF
        librosa.display.specshow(20*np.log10(avg_tf_noisy+1e-8),
                                 sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch, 1])
        axs[ch, 1].set_title("Average TF (Noisy)")

        # Noise-suppressed TF
        librosa.display.specshow(20*np.log10(masked_tf+1e-8),
                                 sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch, 2])
        axs[ch, 2].set_title("Noise-Suppressed TF")

    # Colorbar for masked TF
    #plt.colorbar(axs[0, 2].collections[0], ax=axs[:, 2], format="%+2.0f dB")
    #plt.tight_layout()
    #plt.show()

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import soundfile as sf

# -------------------------------
# Median-based TF filtering
# -------------------------------
def median_tf_filter(tf_maps: np.ndarray, median_threshold: float = 0.5) -> np.ndarray:
    """
    Filters a multi-channel time-frequency representation by applying a
    threshold based on the median and max values across channels.
    """
    abs_tf = np.abs(tf_maps)  # Magnitude of all channels
    median_tf = np.median(abs_tf, axis=0)  # Median magnitude across channels
    max_val = np.max(abs_tf, axis=0)       # Max magnitude across channels

    # Create a mask where the median is a significant portion of the max
    mask = median_tf >= median_threshold * max_val

    # Apply the mask to the median representation
    median_masked_tf = median_tf * mask

    return median_tf, median_masked_tf

# -------------------------------
# Demo pipeline
# -------------------------------
if __name__ == "__main__":
    # ===================================================================
    # >> STEP 1: SET YOUR AUDIO FILE PATH HERE <<
    # ===================================================================
    audio_file_path = "/content/DroneSound_noMuff.wav"  # <-- Update this
    # ===================================================================

    try:
        # Load audio (preserves original channels)
        print(f"Loading audio file: {audio_file_path}")
        y, sr = sf.read(audio_file_path)  # y shape: (samples,) or (samples, channels)
    except FileNotFoundError:
        print(f"Error: The file '{audio_file_path}' was not found.")
        exit()
    except Exception as e:
        print(f"An error occurred while loading the audio file: {e}")
        exit()

    # Ensure y is 2D: shape = (channels, samples)
    if y.ndim == 1:
        y_multi = y[np.newaxis, :]  # Mono -> 1 channel
    else:
        y_multi = y.T  # Shape: (channels, samples)

    num_channels = y_multi.shape[0]
    print(f"Audio loaded with {num_channels} channel(s) at {sr} Hz.")

    # STFT for each channel
    n_fft = 1024
    hop_length = 512
    tf_maps = np.array([librosa.stft(y_multi[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)])

    # Apply the median filtering function
    median_tf, median_masked_tf = median_tf_filter(tf_maps, median_threshold=0.5)

    # -------------------------------
    # PLOT RESULTS
    # -------------------------------
    fig, axs = plt.subplots(num_channels + 2, 1, figsize=(12, 3 * (num_channels + 2)), sharex=True, sharey=True)

    # Plot individual channel spectrograms
    for ch in range(num_channels):
        D = 20 * np.log10(np.abs(tf_maps[ch]) + 1e-8)
        img = librosa.display.specshow(D, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch])
        axs[ch].set_title(f"Channel {ch + 1}")
        axs[ch].label_outer()

    # Plot median across channels
    median_db = 20 * np.log10(median_tf + 1e-8)
    librosa.display.specshow(median_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[num_channels])
    axs[num_channels].set_title("Median Across Channels (Noise Reduced)")
    axs[num_channels].label_outer()

    # Plot median-filtered TF
    masked_db = 20 * np.log10(median_masked_tf + 1e-8)
    librosa.display.specshow(masked_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[num_channels + 1])
    axs[num_channels + 1].set_title("Median Filtered TF (Common Signal Preserved)")

    # Single colorbar for all plots
    #fig.colorbar(img, ax=axs, format='%+2.0f dB', label='Decibels (dB)')

    plt.tight_layout()
    plt.show()

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from typing import Tuple
import soundfile as sf  # safer for multi-channel WAV

# -------------------------------
# Core function (squared coherence filter)
# -------------------------------
def process_multi_channel_coherence_squared(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray]:
    """
    tf_maps: (K, L, M) complex STFT maps, K=channels, L=freq bins, M=time frames
    calc_coherence: function(x,y) -> coherence matrix (L,M)
    Applies squared coherence mask to preserve only strong coherent components.
    """
    K, L, M = tf_maps.shape
    if K < 2:
        raise ValueError("At least 2 channels are required for coherence analysis")

    num_pairs = K * (K - 1) // 2
    if logging:
        print(f"[COHERENCE] Processing {K} channels, {num_pairs} channel pairs")
        print(f"[COHERENCE] TF map shape: {L}×{M}")

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            if logging:
                print(f"[COHERENCE] Pair ({i}, {j})")

            coherence = calc_coherence(tf_maps[i], tf_maps[j])  # (L, M)
            coherence_streams[pair_idx] = coherence

            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    # -------------------------
    # Squared coherence mask
    # -------------------------
    coherence_mask = (max_coherence**2) >= coherence_threshold

    # Average TF from the best coherent pair at each bin
    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0  # suppressed

    if logging:
        coherence_stats = {
            'mean': np.mean(max_coherence),
            'std': np.std(max_coherence),
            'min': np.min(max_coherence),
            'max': np.max(max_coherence),
            'above_threshold': np.sum(coherence_mask) / (L * M) * 100
        }
        print("[COHERENCE] Stats (Squared Filter):")
        for k, v in coherence_stats.items():
            print(f"  {k}: {v:.3f}" if isinstance(v, float) else f"  {k}: {v}")

    return average_tf_map, coherence_mask


def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    """Convert linear pair index back to channel indices (i,j)."""
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j


# -------------------------------
# Example coherence calculator
# -------------------------------
def simple_coherence(x: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Pixel-wise coherence: |X*Y| / (|X||Y|)"""
    eps = 1e-8
    return np.abs(x * np.conj(y)) / (np.abs(x) * np.abs(y) + eps)


# -------------------------------
# Demo pipeline
# -------------------------------
if __name__ == "__main__":
    audio_file_path = "/content/DroneSound_noMuff.wav"  # <-- Update this
    y, sr = sf.read(audio_file_path)  # preserves all channels

    # Ensure shape (channels, samples)
    if y.ndim == 1:
        y = y[np.newaxis, :]
    else:
        y = y.T

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    # STFT per channel
    n_fft = 1024
    hop_length = 512
    tf_maps = np.array([librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)])

    # Apply squared coherence filter
    avg_tf_map, coherence_mask = process_multi_channel_coherence_squared(
        tf_maps, simple_coherence, coherence_threshold=0.36, logging=True
    )
    # Note: threshold reduced because of squaring

    # -------------------------------
    # PLOTS
    # -------------------------------
    fig, axs = plt.subplots(num_channels, 3, figsize=(15, 3*num_channels))
    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    masked_tf = np.abs(avg_tf_map)

    for ch in range(num_channels):
        librosa.display.specshow(20*np.log10(np.abs(tf_maps[ch])+1e-8),
                                 sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch, 0])
        axs[ch, 0].set_title(f"Channel {ch} TF Map")

        librosa.display.specshow(20*np.log10(avg_tf_noisy+1e-8),
                                 sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch, 1])
        axs[ch, 1].set_title("Average TF (Noisy)")

        librosa.display.specshow(20*np.log10(masked_tf+1e-8),
                                 sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=axs[ch, 2])
        axs[ch, 2].set_title("Noise-Suppressed TF (Squared Filter)")

    # Colorbar for masked TF
    plt.colorbar(axs[0, 2].collections[0], ax=axs[:, 2], format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from typing import Optional, Tuple

def apply_squaring_filter(audio_data: np.ndarray) -> np.ndarray:
    """
    Applies a squaring filter to the audio data.

    This is a non-linear operation where each sample is multiplied by itself.
    It emphasizes higher-amplitude signal components.

    Parameters
    ----------
    audio_data : np.ndarray
        The input audio waveform.

    Returns
    -------
    np.ndarray
        The squared audio waveform.
    """
    print("Applying squaring filter to the audio waveform.")
    return np.square(audio_data)


def create_spectrogram(
    audio_data: np.ndarray,
    sample_rate: int,
    n_fft: int = 2048,
    hop_length: int = 512,
    window: str = 'hann',
    cmap: str = 'viridis',
    figsize: Tuple[int, int] = (12, 5),
    title: Optional[str] = None,
    logging: bool = False,
    yscale: str = 'log',
):
    """
    Create and plot a spectrogram for the given audio data.
    """
    # Compute STFT
    S_complex = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length, window=window)
    S_mag = np.abs(S_complex)

    # Convert to dB if logging is True
    S_plot = librosa.amplitude_to_db(S_mag, ref=np.max) if logging else S_mag

    # Frequency and time axes
    freqs = librosa.fft_frequencies(sr=sample_rate, n_fft=n_fft)
    times = librosa.frames_to_time(np.arange(S_mag.shape[1]), sr=sample_rate, hop_length=hop_length)

    # Plot
    plt.figure(figsize=figsize)
    librosa.display.specshow(S_plot, sr=sample_rate, hop_length=hop_length,
                             x_axis='time', y_axis='log' if yscale=='log' else 'linear',
                             cmap=cmap)
    plt.colorbar(format='%+2.0f dB' if logging else '%0.2f', label='Amplitude' if not logging else 'dB')
    if title:
        plt.title(title)
    plt.tight_layout()
    plt.show()

    return S_mag, freqs, times

# --- Example usage ---
# Load your audio
# Make sure to replace this path with the actual path to your audio file
try:
    file = "/content/DroneSound_noMuff.wav"
    y, sr = librosa.load(file, sr=None, mono=False)
except FileNotFoundError:
    print(f"Audio file not found at {file}. Using a sample audio file from librosa.")
    # Fallback to a librosa example audio if the file is not found
    file = librosa.ex('trumpet')
    y, sr = librosa.load(file, sr=None, mono=False)


# Handle multi-channel audio (plot channel 1)
if y.ndim > 1:
    y_channel = y[0]  # first channel
else:
    y_channel = y

# 1. Create and show the ORIGINAL spectrogram
create_spectrogram(
    audio_data=y_channel,
    sample_rate=sr,
    n_fft=2048,
    hop_length=512,
    logging=True,
    title="Original Spectrogram"
)

# 2. Apply the squaring filter to the waveform
y_squared = apply_squaring_filter(y_channel)

# 3. Create and show the spectrogram of the SQUARED signal
create_spectrogram(
    audio_data=y_squared,
    sample_rate=sr,
    n_fft=2048,
    hop_length=512,
    logging=True,
    title="Spectrogram After Squaring Filter"
)

import numpy as np
import librosa
import matplotlib.pyplot as plt
from typing import Tuple
import soundfile as sf  # safer for multi-channel WAV

# -------------------------------
# Core function (noise suppression with coherence)
# -------------------------------
def process_multi_channel_coherence(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    tf_maps: (K, L, M) complex STFT maps, K=channels, L=freq bins, M=time frames
    calc_coherence: function(x,y) -> coherence matrix (L,M)
    """
    K, L, M = tf_maps.shape
    if K < 2:
        raise ValueError("At least 2 channels are required for coherence analysis")

    num_pairs = K * (K - 1) // 2
    if logging:
        print(f"[COHERENCE] Processing {K} channels, {num_pairs} channel pairs")
        print(f"[COHERENCE] TF map shape: {L}×{M}")

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            if logging:
                print(f"[COHERENCE] Pair ({i}, {j})")

            coherence = calc_coherence(tf_maps[i], tf_maps[j])  # (L, M)
            coherence_streams[pair_idx] = coherence

            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    # Threshold mask
    coherence_mask = max_coherence >= coherence_threshold

    # Average TF from the best coherent pair at each bin
    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0  # noise suppressed

    if logging:
        coherence_stats = {
            'mean': np.mean(max_coherence),
            'std': np.std(max_coherence),
            'min': np.min(max_coherence),
            'max': np.max(max_coherence),
            'above_threshold': np.sum(coherence_mask) / (L * M) * 100
        }
        print("[COHERENCE] Stats:")
        for k, v in coherence_stats.items():
            print(f"  {k}: {v:.3f}" if isinstance(v, float) else f"  {k}: {v}")

    return average_tf_map, coherence_mask, best_pair_indices


def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    """Convert linear pair index back to channel indices (i,j)."""
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j

# -------------------------------
# Example coherence calculator
# -------------------------------
def simple_coherence(x: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Pixel-wise coherence: |X*Y| / (|X||Y|)"""
    eps = 1e-8
    return np.abs(x * np.conj(y)) / (np.abs(x) * np.abs(y) + eps)

# -------------------------------
# Demo pipeline with plotting
# -------------------------------
if __name__ == "__main__":
    # ------------------------------
    # LOAD YOUR MULTI-CHANNEL AUDIO
    # ------------------------------
    audio_file_path = "/content/Drone1_trimmed.wav"  # <-- Update this
    y, sr = sf.read(audio_file_path)  # preserves all channels

    # Ensure y is shape (channels, samples)
    if y.ndim == 1:  # mono
        y = y[np.newaxis, :]
    else:
        y = y.T  # shape: (channels, samples)

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    # ------------------------------
    # FIXED STFT HANDLING
    # ------------------------------
    n_fft = 4096
    hop_length = n_fft // 2

    # Compute STFTs individually
    stft_list = [librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)]

    # Find max number of frames across channels
    max_frames = max(stft.shape[1] for stft in stft_list)
    freq_bins = stft_list[0].shape[0]

    # Pad/crop to align all channels
    tf_maps = np.zeros((num_channels, freq_bins, max_frames), dtype=np.complex64)
    for ch in range(num_channels):
        stft = stft_list[ch]
        frames = stft.shape[1]
        tf_maps[ch, :, :frames] = stft  # pads if shorter

    # ------------------------------
    # PROCESS COHERENCE
    # ------------------------------
    avg_tf_map, coherence_mask, bm = process_multi_channel_coherence(
        tf_maps, simple_coherence, coherence_threshold=0.6, logging=True
    )

    # -------------------------------
    # PLOTS USING imshow
    # -------------------------------
    fig, axs = plt.subplots(num_channels, 4, figsize=(20, 4*num_channels))

    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    masked_tf = np.abs(avg_tf_map)

    for ch in range(num_channels):
        # Raw TF per channel
        im0 = axs[ch, 0].imshow(20*np.log10(np.abs(tf_maps[ch])+1e-8),
                                 origin='lower', aspect='auto')
        axs[ch, 0].set_title(f"Channel {ch} TF Map")
        axs[ch, 0].set_xlabel("Time [frames]")
        axs[ch, 0].set_ylabel("Frequency bins")
        fig.colorbar(im0, ax=axs[ch, 0], format="%+2.0f dB")

        # Average TF
        im1 = axs[ch, 1].imshow(20*np.log10(avg_tf_noisy+1e-8),
                                 origin='lower', aspect='auto')
        axs[ch, 1].set_title("Average TF (Noisy)")
        axs[ch, 1].set_xlabel("Time [frames]")
        axs[ch, 1].set_ylabel("Frequency bins")
        fig.colorbar(im1, ax=axs[ch, 1], format="%+2.0f dB")

        # Noise-suppressed TF
        im2 = axs[ch, 2].imshow(20*np.log10(masked_tf+1e-8),
                                 origin='lower', aspect='auto')
        axs[ch, 2].set_title("Noise-Suppressed TF")
        axs[ch, 2].set_xlabel("Time [frames]")
        axs[ch, 2].set_ylabel("Frequency bins")
        fig.colorbar(im2, ax=axs[ch, 2], format="%+2.0f dB")

        # Best pair indices (debug view)
        im3 = axs[ch, 3].imshow(bm,
                                 origin='lower', aspect='auto')
        axs[ch, 3].set_title("Best Pair Indices")
        axs[ch, 3].set_xlabel("Time [frames]")
        axs[ch, 3].set_ylabel("Frequency bins")
        fig.colorbar(im3, ax=axs[ch, 3])

    plt.tight_layout()
    plt.show()

import numpy as np
import librosa
import matplotlib.pyplot as plt
import soundfile as sf
from typing import Tuple

# -------------------------------
# Helper functions
# -------------------------------
def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    """Convert linear pair index back to channel indices (i,j)."""
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j

def simple_coherence(x: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Pixel-wise coherence: |X*Y| / (|X||Y|)"""
    eps = 1e-8
    return np.abs(x * np.conj(y)) / (np.abs(x) * np.abs(y) + eps)

# -------------------------------
# Core function
# -------------------------------
def process_multi_channel_coherence(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    tf_maps: (K, L, M) complex STFT maps
    calc_coherence: function(x,y) -> (L,M) coherence map
    """
    K, L, M = tf_maps.shape
    if K < 2:
        raise ValueError("At least 2 channels required for coherence analysis")

    num_pairs = K * (K - 1) // 2
    if logging:
        print(f"[COHERENCE] Processing {K} channels, {num_pairs} channel pairs")
        print(f"[COHERENCE] TF map shape: {L}×{M}")

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            if logging:
                print(f"[COHERENCE] Pair ({i}, {j})")

            coherence = calc_coherence(tf_maps[i], tf_maps[j])
            coherence_streams[pair_idx] = coherence

            # --- Update max coherence and best pair indices ---
            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    # Threshold mask
    coherence_mask = max_coherence >= coherence_threshold

    # Average TF from the best coherent pair at each bin
    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0

    return average_tf_map, coherence_mask, best_pair_indices

# -------------------------------
# Main pipeline
# -------------------------------
if __name__ == "__main__":
    audio_file_path = "/content/Drone1_trimmed.wav"  # <-- Update path
    y, sr = sf.read(audio_file_path)

    # Ensure shape (channels, samples)
    if y.ndim == 1:
        y = y[np.newaxis, :]
    else:
        y = y.T

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    # STFT parameters
    n_fft = 4096
    hop_length = n_fft // 2

    # Compute STFTs
    stft_list = [librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)]
    max_frames = max(stft.shape[1] for stft in stft_list)
    freq_bins = stft_list[0].shape[0]

    # Align TF maps
    tf_maps = np.zeros((num_channels, freq_bins, max_frames), dtype=np.complex64)
    for ch in range(num_channels):
        stft = stft_list[ch]
        tf_maps[ch, :, :stft.shape[1]] = stft

    # Process coherence
    avg_tf_map, coherence_mask, bm = process_multi_channel_coherence(
        tf_maps, simple_coherence, coherence_threshold=0.6, logging=True
    )

    # -------------------------------
    # Plot raw TF maps (full length) per channel
    # -------------------------------
    for ch in range(num_channels):
        plt.figure(figsize=(14, 5))
        plt.imshow(20*np.log10(np.abs(tf_maps[ch]) + 1e-8),
                   origin='lower', aspect='auto')
        plt.title(f"Channel {ch} TF Map")
        plt.xlabel("Time [frames]")
        plt.ylabel("Frequency bins")
        plt.colorbar(format="%+2.0f dB")
        plt.tight_layout()
        plt.show()

    # -------------------------------
    # Summary plots
    # -------------------------------
    # Average TF
    plt.figure(figsize=(14, 5))
    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    plt.imshow(20*np.log10(avg_tf_noisy + 1e-8), origin='lower', aspect='auto')
    plt.title("Average Noisy TF Map")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency bins")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # Noise-suppressed TF
    plt.figure(figsize=(14, 5))
    masked_tf = np.abs(avg_tf_map)
    plt.imshow(20*np.log10(masked_tf + 1e-8), origin='lower', aspect='auto')
    plt.title("Noise-Suppressed TF Map")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency bins")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # Best pair indices
    plt.figure(figsize=(14, 5))
    plt.imshow(bm, origin='lower', aspect='auto', cmap='tab20')  # discrete colors
    plt.title("Best Pair Indices (per TF bin)")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency bins")
    plt.colorbar()
    plt.tight_layout()
    plt.show()

import numpy as np
import librosa
import matplotlib.pyplot as plt
import soundfile as sf
from typing import Tuple

# -------------------------------
# Helper functions
# -------------------------------
def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    """Convert linear pair index back to channel indices (i,j)."""
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j

def smooth_coherence(x: np.ndarray, y: np.ndarray, win_size=5) -> np.ndarray:
    """
    Smoothed pixel-wise coherence over a small time neighborhood.
    x, y: STFT matrices (freq_bins x time_frames)
    win_size: smoothing window over time axis
    Returns: coherence (freq_bins x time_frames) in [0,1]
    """
    eps = 1e-8
    L, M = x.shape
    coh = np.zeros((L, M))
    for l in range(L):
        for m in range(M):
            t_start = max(0, m - win_size//2)
            t_end = min(M, m + win_size//2 + 1)
            num = np.abs(np.sum(x[l, t_start:t_end] * np.conj(y[l, t_start:t_end])))**2
            den = np.sum(np.abs(x[l, t_start:t_end])**2) * np.sum(np.abs(y[l, t_start:t_end])**2) + eps
            coh[l, m] = num / den
    return np.clip(coh, 0, 1)

# -------------------------------
# Core function
# -------------------------------
def process_multi_channel_coherence(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    K, L, M = tf_maps.shape
    if K < 2:
        raise ValueError("At least 2 channels required for coherence analysis")

    num_pairs = K * (K - 1) // 2
    if logging:
        print(f"[COHERENCE] Processing {K} channels, {num_pairs} channel pairs")
        print(f"[COHERENCE] TF map shape: {L}×{M}")

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            if logging:
                print(f"[COHERENCE] Pair ({i}, {j})")

            coherence = calc_coherence(tf_maps[i], tf_maps[j])
            coherence_streams[pair_idx] = coherence

            # --- Plot coherence map for this pair ---
            plt.figure(figsize=(14, 5))
            plt.imshow(coherence, origin='lower', aspect='auto', cmap='viridis', vmin=0, vmax=1)
            plt.title(f"Coherence Map for Pair {pair_idx} (Channels {i},{j})")
            plt.xlabel("Time [frames]")
            plt.ylabel("Frequency bins")
            plt.colorbar(label="Coherence")
            plt.tight_layout()
            plt.show()

            # --- Update max coherence and best pair indices ---
            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    # Threshold mask
    coherence_mask = max_coherence >= coherence_threshold

    # Average TF from the best coherent pair at each bin
    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0

    return average_tf_map, coherence_mask, best_pair_indices

# -------------------------------
# Main pipeline
# -------------------------------
if __name__ == "__main__":
    audio_file_path = "/content/Drone1_trimmed.wav"  # <-- Update path
    y, sr = sf.read(audio_file_path)

    if y.ndim == 1:
        y = y[np.newaxis, :]
    else:
        y = y.T

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    n_fft = 4096
    hop_length = n_fft // 2

    # Compute STFT for each channel
    stft_list = [librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)]
    max_frames = max(stft.shape[1] for stft in stft_list)
    freq_bins = stft_list[0].shape[0]

    # Align all channels (pad shorter ones)
    tf_maps = np.zeros((num_channels, freq_bins, max_frames), dtype=np.complex64)
    for ch in range(num_channels):
        stft = stft_list[ch]
        tf_maps[ch, :, :stft.shape[1]] = stft

    # -------------------------------
    # Process coherence with smoothed coherence
    # -------------------------------
    avg_tf_map, coherence_mask, bm = process_multi_channel_coherence(
        tf_maps, lambda x,y: smooth_coherence(x, y, win_size=7),
        coherence_threshold=0.6, logging=True
    )

    # -------------------------------
    # Plot raw TF maps (full length)
    # -------------------------------
    for ch in range(num_channels):
        plt.figure(figsize=(14, 5))
        plt.imshow(20*np.log10(np.abs(tf_maps[ch]) + 1e-8),
                   origin='lower', aspect='auto')
        plt.title(f"Channel {ch} TF Map")
        plt.xlabel("Time [frames]")
        plt.ylabel("Frequency bins")
        plt.colorbar(format="%+2.0f dB")
        plt.tight_layout()
        plt.show()

    # -------------------------------
    # Summary plots
    # -------------------------------
    # Average TF
    plt.figure(figsize=(14, 5))
    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    plt.imshow(20*np.log10(avg_tf_noisy + 1e-8), origin='lower', aspect='auto')
    plt.title("Average TF Map")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency bins")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # Noise-suppressed TF
    plt.figure(figsize=(14, 5))
    masked_tf = np.abs(avg_tf_map)
    plt.imshow(20*np.log10(masked_tf + 1e-8), origin='lower', aspect='auto')
    plt.title("Best Pair TF Map")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency bins")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # Best pair indices (color-coded)
    plt.figure(figsize=(14, 5))
    masked_bm = np.where(coherence_mask, bm, np.nan)
    plt.imshow(masked_bm, origin='lower', aspect='auto', cmap='tab10')
    plt.title("Best Pair Indices (masked by coherence threshold)")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency bins")
    plt.colorbar()
    plt.tight_layout()
    plt.show()

sr

import numpy as np
import librosa
import matplotlib.pyplot as plt
import soundfile as sf
from typing import Tuple

# -------------------------------
# Helper functions
# -------------------------------
def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j

def smooth_coherence(x: np.ndarray, y: np.ndarray, win_size=5) -> np.ndarray:
    eps = 1e-8
    L, M = x.shape
    coh = np.zeros((L, M))
    for l in range(L):
        for m in range(M):
            t_start = max(0, m - win_size//2)
            t_end = min(M, m + win_size//2 + 1)
            num = np.abs(np.sum(x[l, t_start:t_end] * np.conj(y[l, t_start:t_end])))**2
            den = np.sum(np.abs(x[l, t_start:t_end])**2) * np.sum(np.abs(y[l, t_start:t_end])**2) + eps
            coh[l, m] = num / den
    return np.clip(coh, 0, 1)

# -------------------------------
# Core function
# -------------------------------
def process_multi_channel_coherence(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    K, L, M = tf_maps.shape
    if K < 2:
        raise ValueError("At least 2 channels required for coherence analysis")

    num_pairs = K * (K - 1) // 2
    if logging:
        print(f"[COHERENCE] Processing {K} channels, {num_pairs} channel pairs")
        print(f"[COHERENCE] TF map shape: {L}×{M}")

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            if logging:
                print(f"[COHERENCE] Pair ({i}, {j})")

            coherence = calc_coherence(tf_maps[i], tf_maps[j])
            coherence_streams[pair_idx] = coherence

            # Plot coherence map for this pair
            plt.figure(figsize=(14, 5))
            plt.imshow(coherence, origin='lower', aspect='auto', cmap='viridis', vmin=0, vmax=1,
                       extent=[0, M*hop_length/sr, 0, sr/2])
            plt.title(f"Coherence Map for Pair {pair_idx} (Channels {i},{j})")
            plt.xlabel("Time [s]")
            plt.ylabel("Frequency [Hz]")
            plt.colorbar(label="Coherence")
            plt.tight_layout()
            plt.show()

            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    coherence_mask = max_coherence >= coherence_threshold

    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0

    return average_tf_map, coherence_mask, best_pair_indices

# -------------------------------
# Main pipeline
# -------------------------------
if __name__ == "__main__":
    audio_file_path = "/content/Drone1_trimmed.wav"
    y, sr = sf.read(audio_file_path)

    if y.ndim == 1:
        y = y[np.newaxis, :]
    else:
        y = y.T

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    n_fft = 4096
    hop_length = n_fft // 2

    # Compute STFT for each channel
    stft_list = [librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)]
    max_frames = max(stft.shape[1] for stft in stft_list)
    freq_bins = stft_list[0].shape[0]

    tf_maps = np.zeros((num_channels, freq_bins, max_frames), dtype=np.complex64)
    for ch in range(num_channels):
        stft = stft_list[ch]
        tf_maps[ch, :, :stft.shape[1]] = stft

    # Process coherence
    avg_tf_map, coherence_mask, bm = process_multi_channel_coherence(
        tf_maps, lambda x,y: smooth_coherence(x, y, win_size=7),
        coherence_threshold=0.6, logging=True
    )

    # Frequency and time axes
    freq_axis = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    time_axis = np.arange(max_frames) * hop_length / sr  # in seconds

    # Plot raw TF maps
    for ch in range(num_channels):
        plt.figure(figsize=(14, 5))
        plt.imshow(20*np.log10(np.abs(tf_maps[ch]) + 1e-8),
                   origin='lower', aspect='auto',
                   extent=[time_axis[0], time_axis[-1], freq_axis[0], freq_axis[-1]])
        plt.title(f"Channel {ch} TF Map")
        plt.xlabel("Time [s]")
        plt.ylabel("Frequency [Hz]")
        plt.colorbar(format="%+2.0f dB")
        plt.tight_layout()
        plt.show()

    # Average TF
    plt.figure(figsize=(14, 5))
    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    plt.imshow(20*np.log10(avg_tf_noisy + 1e-8), origin='lower', aspect='auto',
               extent=[time_axis[0], time_axis[-1], freq_axis[0], freq_axis[-1]])
    plt.title("Average TF Map")
    plt.xlabel("Time [s]")
    plt.ylabel("Frequency [Hz]")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # Noise-suppressed TF
    plt.figure(figsize=(14, 5))
    masked_tf = np.abs(avg_tf_map)
    plt.imshow(20*np.log10(masked_tf + 1e-8), origin='lower', aspect='auto',
               extent=[time_axis[0], time_axis[-1], freq_axis[0], freq_axis[-1]])
    plt.title("Best Pair TF Map")
    plt.xlabel("Time [s]")
    plt.ylabel("Frequency [Hz]")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # Best pair indices
    plt.figure(figsize=(14, 5))
    masked_bm = np.where(coherence_mask, bm, np.nan)
    plt.imshow(masked_bm, origin='lower', aspect='auto',
               extent=[time_axis[0], time_axis[-1], freq_axis[0], freq_axis[-1]], cmap='tab10')
    plt.title("Best Pair Indices (masked by coherence threshold)")
    plt.xlabel("Time [s]")
    plt.ylabel("Frequency [Hz]")
    plt.colorbar()
    plt.tight_layout()
    plt.show()

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import soundfile as sf
from typing import Tuple

# -------------------------------
# Helper functions
# -------------------------------
def _pair_index_to_channels(pair_idx: int, K: int) -> Tuple[int, int]:
    """Convert linear pair index back to channel indices (i,j)."""
    i = 0
    remaining = pair_idx
    while remaining >= (K - 1 - i):
        remaining -= (K - 1 - i)
        i += 1
    j = i + 1 + remaining
    return i, j

def smooth_coherence(x: np.ndarray, y: np.ndarray, win_size=5) -> np.ndarray:
    """Smoothed pixel-wise coherence."""
    eps = 1e-8
    L, M = x.shape
    coh = np.zeros((L, M))
    for l in range(L):
        for m in range(M):
            t_start = max(0, m - win_size//2)
            t_end = min(M, m + win_size//2 + 1)
            num = np.abs(np.sum(x[l, t_start:t_end] * np.conj(y[l, t_start:t_end])))**2
            den = np.sum(np.abs(x[l, t_start:t_end])**2) * np.sum(np.abs(y[l, t_start:t_end])**2) + eps
            coh[l, m] = num / den
    return np.clip(coh, 0, 1)

# -------------------------------
# Core function
# -------------------------------
def process_multi_channel_coherence(
        tf_maps: np.ndarray,
        calc_coherence: callable,
        coherence_threshold: float = 0.5,
        sr: int = 16000,
        hop_length: int = 2048,
        logging: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    K, L, M = tf_maps.shape
    num_pairs = K * (K - 1) // 2

    coherence_streams = np.zeros((num_pairs, L, M))
    max_coherence = np.zeros((L, M))
    best_pair_indices = np.zeros((L, M), dtype=int)

    freqs = np.linspace(0, sr/2, L)  # frequency axis in Hz

    pair_idx = 0
    for i in range(K):
        for j in range(i + 1, K):
            coherence = calc_coherence(tf_maps[i], tf_maps[j])
            coherence_streams[pair_idx] = coherence

            # Plot coherence map for this pair
            plt.figure(figsize=(14, 5))
            plt.imshow(coherence, origin='lower', aspect='auto', cmap='viridis',
                       vmin=0, vmax=1,
                       extent=[0, M, freqs[0], freqs[-1]])
            plt.ylim([0, 8000])  # limit to 8 kHz
            plt.title(f"Coherence Map for Pair {pair_idx} (Channels {i},{j})")
            plt.xlabel("Time [frames]")
            plt.ylabel("Frequency [Hz]")
            plt.colorbar(label="Coherence")
            plt.tight_layout()
            plt.show()

            # Update max coherence
            better_mask = coherence > max_coherence
            max_coherence[better_mask] = coherence[better_mask]
            best_pair_indices[better_mask] = pair_idx
            pair_idx += 1

    coherence_mask = max_coherence >= coherence_threshold

    # Average TF from the best coherent pair
    average_tf_map = np.zeros((L, M), dtype=np.complex64)
    for l in range(L):
        for m in range(M):
            if coherence_mask[l, m]:
                best_pair = best_pair_indices[l, m]
                i, j = _pair_index_to_channels(best_pair, K)
                average_tf_map[l, m] = (tf_maps[i, l, m] + tf_maps[j, l, m]) / 2.0
            else:
                average_tf_map[l, m] = 0.0

    return average_tf_map, coherence_mask, best_pair_indices

# -------------------------------
# Main pipeline
# -------------------------------
if __name__ == "__main__":
    audio_file_path = "/content/Drone1_trimmed.wav"  # update path
    y, sr = sf.read(audio_file_path)

    if y.ndim == 1:
        y = y[np.newaxis, :]
    else:
        y = y.T

    num_channels = y.shape[0]
    print(f"Loaded {num_channels} channels, {y.shape[1]} samples at {sr} Hz")

    n_fft = 4096
    hop_length = n_fft // 2

    # Compute STFT
    stft_list = [librosa.stft(y[ch], n_fft=n_fft, hop_length=hop_length) for ch in range(num_channels)]
    max_frames = max(stft.shape[1] for stft in stft_list)
    freq_bins = stft_list[0].shape[0]

    tf_maps = np.zeros((num_channels, freq_bins, max_frames), dtype=np.complex64)
    for ch in range(num_channels):
        stft = stft_list[ch]
        tf_maps[ch, :, :stft.shape[1]] = stft

    # Process coherence
    avg_tf_map, coherence_mask, bm = process_multi_channel_coherence(
        tf_maps, lambda x, y: smooth_coherence(x, y, win_size=7),
        coherence_threshold=0.6, sr=sr, hop_length=hop_length, logging=True
    )

    # Frequency axis for later
    freqs = np.linspace(0, sr/2, freq_bins)

    # -------------------------------
    # Raw TF maps
    # -------------------------------
    for ch in range(num_channels):
        plt.figure(figsize=(14, 5))
        librosa.display.specshow(20*np.log10(np.abs(tf_maps[ch]) + 1e-8),
                                 sr=sr, hop_length=hop_length,
                                 x_axis="time", y_axis="hz")
        plt.ylim([0, 8000])
        plt.title(f"Channel {ch} TF Map (0–8 kHz)")
        plt.colorbar(format="%+2.0f dB")
        plt.tight_layout()
        plt.show()

    # -------------------------------
    # Average TF Map
    # -------------------------------
    plt.figure(figsize=(14, 5))
    avg_tf_noisy = np.mean(np.abs(tf_maps), axis=0)
    librosa.display.specshow(20*np.log10(avg_tf_noisy + 1e-8),
                             sr=sr, hop_length=hop_length,
                             x_axis="time", y_axis="hz")
    plt.ylim([0, 8000])
    plt.title("Average TF Map (0–8 kHz)")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # -------------------------------
    # Noise-suppressed TF
    # -------------------------------
    plt.figure(figsize=(14, 5))
    masked_tf = np.abs(avg_tf_map)
    librosa.display.specshow(20*np.log10(masked_tf + 1e-8),
                             sr=sr, hop_length=hop_length,
                             x_axis="time", y_axis="hz")
    plt.ylim([0, 8000])
    plt.title("Best Pair TF Map (0–8 kHz)")
    plt.colorbar(format="%+2.0f dB")
    plt.tight_layout()
    plt.show()

    # -------------------------------
    # Best Pair Indices
    # -------------------------------
    plt.figure(figsize=(14, 5))
    masked_bm = np.where(coherence_mask, bm, np.nan)
    plt.imshow(masked_bm, origin='lower', aspect='auto', cmap='tab10',
               extent=[0, bm.shape[1], freqs[0], freqs[-1]])
    plt.ylim([0, 8000])
    plt.title("Best Pair Indices (masked, 0–8 kHz)")
    plt.xlabel("Time [frames]")
    plt.ylabel("Frequency [Hz]")
    plt.colorbar()
    plt.tight_layout()
    plt.show()